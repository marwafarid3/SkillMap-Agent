 from fastapi import FastAPI
from pydantic import BaseModel
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_community.llms import HuggingFacePipeline
from transformers import pipeline
import torch

app = FastAPI(title="AI Track Planning Agent")

# ==============================
# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ Open Source
# ==============================

model_id = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

pipe = pipeline(
    "text-generation",
    model=model_id,
    torch_dtype=torch.float32,
    device_map="auto",
    max_new_tokens=700
)

llm = HuggingFacePipeline(pipeline=pipe)

# ==============================
# Prompt
# ==============================

plan_prompt = PromptTemplate(
    input_variables=["track", "level", "hours", "goal"],
    template="""
Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± ØªÙ‚Ù†ÙŠ Ù…Ø­ØªØ±Ù.

Ø§Ù„Ù…Ø¹Ø·ÙŠØ§Øª:
Ø§Ù„ØªØ±Ø§Ùƒ: {track}
Ø§Ù„Ù…Ø³ØªÙˆÙ‰: {level}
Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø§Øª ÙŠÙˆÙ…ÙŠÙ‹Ø§: {hours}
Ø§Ù„Ù‡Ø¯Ù: {goal}

Ø£Ù†Ø´Ø¦ Ø®Ø·Ø© ØªØ¹Ù„Ù… Ù…ÙØµÙ„Ø© Ù„Ù…Ø¯Ø© 3 Ø´Ù‡ÙˆØ±.
Ù‚Ø³Ù‘Ù…Ù‡Ø§ Ø¨Ø£Ø³Ø§Ø¨ÙŠØ¹.
Ø§Ø°ÙƒØ±:
- Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
- Ù…ØµØ§Ø¯Ø± ØªØ¹Ù„Ù… Ù…Ø¬Ø§Ù†ÙŠØ©
- Ù…Ø´Ø§Ø±ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ©
- milestones ÙˆØ§Ø¶Ø­Ø©
"""
)

plan_chain = LLMChain(llm=llm, prompt=plan_prompt)

# ==============================
# Session Storage
# ==============================

sessions = {}

class StartRequest(BaseModel):
    user_id: str
    track: str

class AnswerRequest(BaseModel):
    user_id: str
    answer: str

# ==============================
# Endpoints
# ==============================

@app.get("/")
def home():
    return {"message": "AI Track Agent Running ğŸš€"}

@app.post("/start")
def start_agent(data: StartRequest):
    sessions[data.user_id] = {
        "track": data.track,
        "step": 1
    }

    return {"question": "Ù…Ø³ØªÙˆØ§Ùƒ Ø¥ÙŠÙ‡ØŸ (Ù…Ø¨ØªØ¯Ø¦ - Ù…ØªÙˆØ³Ø· - Ù…ØªÙ‚Ø¯Ù…)"}

@app.post("/answer")
def answer_question(data: AnswerRequest):

    user = sessions.get(data.user_id)

    if not user:
        return {"error": "Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø£ÙˆÙ„ Ù…Ù† /start"}

    step = user["step"]

    if step == 1:
        user["level"] = data.answer
        user["step"] = 2
        return {"question": "ÙƒØ§Ù… Ø³Ø§Ø¹Ø© ØªÙ‚Ø¯Ø± ØªØ°Ø§ÙƒØ± ÙŠÙˆÙ…ÙŠÙ‹Ø§ØŸ"}

    elif step == 2:
        user["hours"] = data.answer
        user["step"] = 3
        return {"question": "Ù‡Ø¯ÙÙƒ Ø¥ÙŠÙ‡ Ù…Ù† Ø§Ù„ØªØ±Ø§Ùƒ Ø¯Ù‡ØŸ"}

    elif step == 3:
        user["goal"] = data.answer

        plan = plan_chain.run({
            "track": user["track"],
            "level": user["level"],
            "hours": user["hours"],
            "goal": user["goal"]
        })

        sessions.pop(data.user_id)

        return {
            "final_plan": plan
        }